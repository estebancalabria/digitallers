# Glosario de Terminos

* **Contexto** : El contexto en modelos de lenguaje se refiere a la información previa que el modelo utiliza para generar respuestas coherentes y relevantes. Es la clave para que una IA entienda el significado de un mensaje en relación con lo que ya se ha dicho en una conversación o con datos previos disponibles.
* **DataSet** : En el contexto de la IA es un conjunto de datos utilizado para entrenar un modelo de IA.
* **Deterministico** : Algo deterministico genera siempre la misma salida cuando recibe la misma entrada. Cuando decimos que una IA no es determinista, significa que puede dar respuestas diferentes incluso si se le hace la misma pregunta varias veces en las mismas condiciones..
* **Fine Tunning** : Reentrenado al modelo según mis especificaciones  
* **LLM** : Large Language Model. Modelo de lenguaje como ChatGPT. Los Large Language Models (LLM) son sistemas de inteligencia artificial que utilizan redes neuronales para aprender
  # P
* **Prompt** : Se refiere a una instrucción o fragmento de texto inicial que se proporciona al modelo para guiar su generación de respuesta.
* **Prompt Chaining** : es una técnica en modelos de lenguaje que consiste en dividir una tarea compleja en múltiples pasos, donde cada paso genera una salida que sirve como entrada para el siguiente. Básicamente, se trata de encadenar prompts para mejorar la coherencia y precisión de la respuesta final.
* **Prompt Engineering** : La ingeniería de prompts es una estrategia utilizada en la interacción con modelos de lenguaje para diseñar y ajustar cuidadosamente las instrucciones iniciales o prompts.
---
* **Red Neuronal** : es un modelo computacional inspirado en la estructura y el funcionamiento del cerebro humano. Su objetivo principal es aprender patrones y relaciones en los datos, permitiéndole realizar tareas como clasificación, predicción, reconocimiento de voz o imágenes, y generación de texto, entre otras.
* **System Prompt** : es una instrucción inicial que se le da al modelo de lenguaje (como ChatGPT) para definir su comportamiento, tono y rol antes de que empiece la conversación con el usuario.
---
# T
* **Tamaño del modelo** : El tamaño de un modelo de lenguaje (LLM, por sus siglas en inglés) se refiere generalmente a la cantidad de parámetros que contiene. Los parámetros son los valores que el modelo ajusta durante el entrenamiento y que definen cómo responde a las entradas. Cuantos más parámetros tenga un modelo, más capacidad tiene para aprender patrones complejos, aunque también requiere más recursos para entrenar y ejecutar.
* **Temperature** : Parámetro de los LLM que controla el nivel de aleatoriedad o creatividad en las respuestas generadas. (0 respuestas mas predecibles, 1 respuestas mas creativas)
* **Token** : La parte mas chica en la que se puede cortar una palabra
* **TopP** : Parametro de los LLM decide cuántas palabras posibles se consideran al responder.Si es bajo (ej. 0.1): solo se usan las más seguras. Si es alto (ej. 0.9): se permite más variedad.
---
# V
* **Ventana de Contexto** (Tamaño de Contexto) :  La ventana de contexto o tamaño de contexto en modelos de lenguaje se refiere a la cantidad de tokens que el modelo puede procesar y recordar dentro de una sola conversación o solicitud. Es fundamental porque determina cuánta información previa puede influir en la respuesta generada.
> Por eso ChatGPT en conversaciones largas empieza a perder detalles. Es muy bueno recordando el comienzo de la conversacion y lo ultimo que se dijo
